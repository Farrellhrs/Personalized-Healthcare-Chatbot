{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ed6366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2081, 2)\n",
      "Unique intents: 11\n",
      "\n",
      "Label mapping:\n",
      "cek_data_customer: 0\n",
      "cek_golongan_darah: 1\n",
      "detail_dokter: 2\n",
      "detail_preskripsi_obat: 3\n",
      "hasil_lab_detail: 4\n",
      "hasil_lab_ringkasan: 5\n",
      "jadwal_dokter: 6\n",
      "riwayat_berobat: 7\n",
      "riwayat_diagnosis: 8\n",
      "riwayat_kondisi_fisik: 9\n",
      "riwayat_preskripsi_obat: 10\n",
      "\n",
      "Total number of classes: 11\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset to get label mappings\n",
    "df = pd.read_csv(r'C:\\Users\\farre\\Documents\\Kuliah\\Magang era\\Project 1\\Training and Test\\Dataset\\inten_umum.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Unique intents: {df['intent'].nunique()}\")\n",
    "\n",
    "# Recreate the label encoder with the same mapping as training\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['intent'])\n",
    "\n",
    "# Display label mapping\n",
    "label_mapping = dict(zip(df['intent'], df['label']))\n",
    "print(\"\\nLabel mapping:\")\n",
    "for intent, label in sorted(label_mapping.items()):\n",
    "    print(f\"{intent}: {label}\")\n",
    "\n",
    "# Reverse mapping for predictions\n",
    "id2label = {v: k for k, v in label_mapping.items()}\n",
    "print(f\"\\nTotal number of classes: {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31340db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\farre\\Documents\\Kuliah\\Magang era\\Project 1\\Model BERT\\model_umum\n",
      "Model loaded successfully!\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model from the latest checkpoint\n",
    "model_path = r\"C:\\Users\\farre\\Documents\\Kuliah\\Magang era\\Project 1\\Model BERT\\model_umum\"  # Using the latest checkpoint\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79d0a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== General Intent Prediction Result ===\n",
      "Input text: 'saya mau cek data customer saya'\n",
      "Predicted intent: cek_data_customer\n",
      "Confidence: 0.9953 (99.53%)\n",
      "Class ID: 0\n",
      "Prediction function ready!\n"
     ]
    }
   ],
   "source": [
    "# Function to predict intent from text\n",
    "def predict_intent(text, model, tokenizer, id2label, max_length=128):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class_id = predictions.argmax().item()\n",
    "        confidence = predictions.max().item()\n",
    "    \n",
    "    # Convert prediction to label\n",
    "    predicted_intent = id2label[predicted_class_id]\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'predicted_intent': predicted_intent,\n",
    "        'confidence': confidence,\n",
    "        'class_id': predicted_class_id\n",
    "    }\n",
    "\n",
    "# Test with a general query\n",
    "test_text = \"saya mau cek data customer saya\"\n",
    "result = predict_intent(test_text, model, tokenizer, id2label)\n",
    "\n",
    "print(\"=== General Intent Prediction Result ===\")\n",
    "print(f\"Input text: '{result['text']}'\")\n",
    "print(f\"Predicted intent: {result['predicted_intent']}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f} ({result['confidence']*100:.2f}%)\")\n",
    "print(f\"Class ID: {result['class_id']}\")\n",
    "\n",
    "print(\"Prediction function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f638596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function ready!\n"
     ]
    }
   ],
   "source": [
    "# Function to predict intent from text\n",
    "def predict_intent(text, model, tokenizer, id2label, max_length=128):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class_id = predictions.argmax().item()\n",
    "        confidence = predictions.max().item()\n",
    "    \n",
    "    # Convert prediction to label\n",
    "    predicted_intent = id2label[predicted_class_id]\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'predicted_intent': predicted_intent,\n",
    "        'confidence': confidence,\n",
    "        'class_id': predicted_class_id\n",
    "    }\n",
    "\n",
    "print(\"Prediction function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff70308",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"saya ingin melihat historis data hasil lab saya\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3949bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction Result ===\n",
      "Input text: 'saya ingin melihat historis data hasil lab saya'\n",
      "Predicted intent: riwayat_kondisi_fisik\n",
      "Confidence: 0.9951 (99.51%)\n",
      "Class ID: 9\n",
      "\n",
      "=== Top 3 Predictions ===\n",
      "1. riwayat_kondisi_fisik - 0.9951 (99.51%)\n",
      "2. hasil_lab_ringkasan - 0.0023 (0.23%)\n",
      "3. riwayat_berobat - 0.0007 (0.07%)\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the text from the first cell\n",
    "result = predict_intent(text, model, tokenizer, id2label)\n",
    "\n",
    "print(\"=== Prediction Result ===\")\n",
    "print(f\"Input text: '{result['text']}'\")\n",
    "print(f\"Predicted intent: {result['predicted_intent']}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f} ({result['confidence']*100:.2f}%)\")\n",
    "print(f\"Class ID: {result['class_id']}\")\n",
    "\n",
    "# Let's also get the top 3 predictions to see alternatives\n",
    "def get_top_predictions(text, model, tokenizer, id2label, top_k=3, max_length=128):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        top_predictions = torch.topk(predictions, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        class_id = top_predictions.indices[0][i].item()\n",
    "        confidence = top_predictions.values[0][i].item()\n",
    "        intent = id2label[class_id]\n",
    "        results.append({\n",
    "            'rank': i+1,\n",
    "            'intent': intent,\n",
    "            'confidence': confidence,\n",
    "            'class_id': class_id\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Get top 3 predictions\n",
    "top_predictions = get_top_predictions(text, model, tokenizer, id2label)\n",
    "\n",
    "print(\"\\n=== Top 3 Predictions ===\")\n",
    "for pred in top_predictions:\n",
    "    print(f\"{pred['rank']}. {pred['intent']} - {pred['confidence']:.4f} ({pred['confidence']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09baf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sentence-transformers already installed\n"
     ]
    }
   ],
   "source": [
    "# Install sentence-transformers if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✅ sentence-transformers already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing sentence-transformers...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sentence-transformers\"])\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✅ sentence-transformers installed successfully\")\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d64cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentence embedding model...\n",
      "✅ Sentence embedding model loaded successfully!\n",
      "Computing embeddings for training examples...\n",
      "Computing embeddings for 'riwayat_kondisi_fisik' (257 examples)...\n",
      "✅ Sentence embedding model loaded successfully!\n",
      "Computing embeddings for training examples...\n",
      "Computing embeddings for 'riwayat_kondisi_fisik' (257 examples)...\n",
      "Computing embeddings for 'cek_golongan_darah' (102 examples)...\n",
      "Computing embeddings for 'cek_data_customer' (101 examples)...\n",
      "Computing embeddings for 'riwayat_diagnosis' (255 examples)...\n",
      "Computing embeddings for 'riwayat_preskripsi_obat' (204 examples)...\n",
      "Computing embeddings for 'detail_preskripsi_obat' (102 examples)...\n",
      "Computing embeddings for 'riwayat_berobat' (203 examples)...\n",
      "Computing embeddings for 'jadwal_dokter' (202 examples)...\n",
      "Computing embeddings for 'detail_dokter' (204 examples)...\n",
      "Computing embeddings for 'hasil_lab_ringkasan' (251 examples)...\n",
      "Computing embeddings for 'cek_golongan_darah' (102 examples)...\n",
      "Computing embeddings for 'cek_data_customer' (101 examples)...\n",
      "Computing embeddings for 'riwayat_diagnosis' (255 examples)...\n",
      "Computing embeddings for 'riwayat_preskripsi_obat' (204 examples)...\n",
      "Computing embeddings for 'detail_preskripsi_obat' (102 examples)...\n",
      "Computing embeddings for 'riwayat_berobat' (203 examples)...\n",
      "Computing embeddings for 'jadwal_dokter' (202 examples)...\n",
      "Computing embeddings for 'detail_dokter' (204 examples)...\n",
      "Computing embeddings for 'hasil_lab_ringkasan' (251 examples)...\n",
      "Computing embeddings for 'hasil_lab_detail' (200 examples)...\n",
      "\n",
      "✅ All training embeddings computed!\n",
      "Total intents: 11\n",
      "  riwayat_kondisi_fisik: 257 examples\n",
      "  cek_golongan_darah: 102 examples\n",
      "  cek_data_customer: 101 examples\n",
      "  riwayat_diagnosis: 255 examples\n",
      "  riwayat_preskripsi_obat: 204 examples\n",
      "  detail_preskripsi_obat: 102 examples\n",
      "  riwayat_berobat: 203 examples\n",
      "  jadwal_dokter: 202 examples\n",
      "  detail_dokter: 204 examples\n",
      "  hasil_lab_ringkasan: 251 examples\n",
      "  hasil_lab_detail: 200 examples\n",
      "Computing embeddings for 'hasil_lab_detail' (200 examples)...\n",
      "\n",
      "✅ All training embeddings computed!\n",
      "Total intents: 11\n",
      "  riwayat_kondisi_fisik: 257 examples\n",
      "  cek_golongan_darah: 102 examples\n",
      "  cek_data_customer: 101 examples\n",
      "  riwayat_diagnosis: 255 examples\n",
      "  riwayat_preskripsi_obat: 204 examples\n",
      "  detail_preskripsi_obat: 102 examples\n",
      "  riwayat_berobat: 203 examples\n",
      "  jadwal_dokter: 202 examples\n",
      "  detail_dokter: 204 examples\n",
      "  hasil_lab_ringkasan: 251 examples\n",
      "  hasil_lab_detail: 200 examples\n"
     ]
    }
   ],
   "source": [
    "# Load sentence embedding model\n",
    "print(\"Loading sentence embedding model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✅ Sentence embedding model loaded successfully!\")\n",
    "\n",
    "# Prepare training embeddings for each intent\n",
    "print(\"Computing embeddings for training examples...\")\n",
    "\n",
    "# Group training examples by intent\n",
    "training_examples_by_intent = {}\n",
    "for _, row in df.iterrows():\n",
    "    intent = row['intent']\n",
    "    text = row['text']\n",
    "    \n",
    "    if intent not in training_examples_by_intent:\n",
    "        training_examples_by_intent[intent] = []\n",
    "    training_examples_by_intent[intent].append(text)\n",
    "\n",
    "# Compute embeddings for all training examples\n",
    "training_embeddings_by_intent = {}\n",
    "for intent, texts in training_examples_by_intent.items():\n",
    "    print(f\"Computing embeddings for '{intent}' ({len(texts)} examples)...\")\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "    training_embeddings_by_intent[intent] = embeddings\n",
    "\n",
    "print(\"\\n✅ All training embeddings computed!\")\n",
    "print(f\"Total intents: {len(training_embeddings_by_intent)}\")\n",
    "for intent, embeddings in training_embeddings_by_intent.items():\n",
    "    print(f\"  {intent}: {embeddings.shape[0]} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45edd53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced prediction function ready!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced prediction function with similarity-based verification\n",
    "def predict_intent_with_similarity(text, model, tokenizer, embedding_model, \n",
    "                                 id2label, training_embeddings_by_intent,\n",
    "                                 confidence_threshold=0.7, similarity_threshold=0.74, \n",
    "                                 max_length=128):\n",
    "    \"\"\"\n",
    "    Predict intent using classifier + similarity verification\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify\n",
    "        model: Trained BERT classifier\n",
    "        tokenizer: BERT tokenizer\n",
    "        embedding_model: Sentence transformer model\n",
    "        id2label: Mapping from class ID to intent label\n",
    "        training_embeddings_by_intent: Precomputed embeddings for training examples\n",
    "        confidence_threshold: Minimum classifier confidence (default: 0.7)\n",
    "        similarity_threshold: Minimum similarity score (default: 0.6)\n",
    "        max_length: Maximum sequence length for tokenization\n",
    "    \n",
    "    Returns:\n",
    "        Dict with prediction results and decision logic\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get classifier prediction\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class_id = predictions.argmax().item()\n",
    "        confidence = predictions.max().item()\n",
    "    \n",
    "    predicted_intent = id2label[predicted_class_id]\n",
    "    \n",
    "    # Step 2: Compute similarity with training examples\n",
    "    query_embedding = embedding_model.encode([text])\n",
    "    \n",
    "    # Get embeddings for the predicted intent\n",
    "    if predicted_intent in training_embeddings_by_intent:\n",
    "        training_embeddings = training_embeddings_by_intent[predicted_intent]\n",
    "        \n",
    "        # Compute cosine similarity with all training examples of predicted intent\n",
    "        similarities = cosine_similarity(query_embedding, training_embeddings)[0]\n",
    "        max_similarity = float(np.max(similarities))\n",
    "        mean_similarity = float(np.mean(similarities))\n",
    "    else:\n",
    "        max_similarity = 0.0\n",
    "        mean_similarity = 0.0\n",
    "    \n",
    "    # Step 3: Apply thresholding logic\n",
    "    meets_confidence = confidence >= confidence_threshold\n",
    "    meets_similarity = max_similarity >= similarity_threshold\n",
    "    \n",
    "    if meets_confidence and meets_similarity:\n",
    "        final_decision = predicted_intent\n",
    "        decision_reason = f\"High confidence ({confidence:.3f}) and similarity ({max_similarity:.3f})\"\n",
    "    else:\n",
    "        final_decision = \"out_of_scope\"\n",
    "        if not meets_confidence and not meets_similarity:\n",
    "            decision_reason = f\"Low confidence ({confidence:.3f}) and similarity ({max_similarity:.3f})\"\n",
    "        elif not meets_confidence:\n",
    "            decision_reason = f\"Low confidence ({confidence:.3f}), similarity OK ({max_similarity:.3f})\"\n",
    "        else:  # not meets_similarity\n",
    "            decision_reason = f\"Confidence OK ({confidence:.3f}), low similarity ({max_similarity:.3f})\"\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'classifier_prediction': predicted_intent,\n",
    "        'classifier_confidence': confidence,\n",
    "        'max_similarity': max_similarity,\n",
    "        'mean_similarity': mean_similarity,\n",
    "        'final_decision': final_decision,\n",
    "        'decision_reason': decision_reason,\n",
    "        'confidence_threshold': confidence_threshold,\n",
    "        'similarity_threshold': similarity_threshold,\n",
    "        'meets_confidence': meets_confidence,\n",
    "        'meets_similarity': meets_similarity\n",
    "    }\n",
    "\n",
    "print(\"✅ Enhanced prediction function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8296a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing enhanced classification system...\n",
      "================================================================================\n",
      "🔍 ENHANCED INTENT CLASSIFICATION RESULT\n",
      "================================================================================\n",
      "📝 Query: 'Tolong tunjukkan semua nilai darah lengkap saya.'\n",
      "\n",
      "🤖 CLASSIFIER RESULTS:\n",
      "   Predicted Intent: cek_data_customer\n",
      "   Confidence: 0.9998 (99.98%)\n",
      "   Meets Confidence Threshold (≥0.7): ✅\n",
      "\n",
      "🔗 SIMILARITY ANALYSIS:\n",
      "   Max Similarity: 0.7430 (74.30%)\n",
      "   Mean Similarity: 0.4936 (49.36%)\n",
      "   Meets Similarity Threshold (≥0.74): ✅\n",
      "\n",
      "🎯 FINAL DECISION:\n",
      "   Result: cek_data_customer\n",
      "   Reason: High confidence (1.000) and similarity (0.743)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Logging function for detailed output\n",
    "def log_prediction_result(result):\n",
    "    \"\"\"Pretty print prediction results with detailed logging\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"🔍 ENHANCED INTENT CLASSIFICATION RESULT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📝 Query: '{result['text']}'\")\n",
    "    print()\n",
    "    print(\"🤖 CLASSIFIER RESULTS:\")\n",
    "    print(f\"   Predicted Intent: {result['classifier_prediction']}\")\n",
    "    print(f\"   Confidence: {result['classifier_confidence']:.4f} ({result['classifier_confidence']*100:.2f}%)\")\n",
    "    print(f\"   Meets Confidence Threshold (≥{result['confidence_threshold']}): {'✅' if result['meets_confidence'] else '❌'}\")\n",
    "    print()\n",
    "    print(\"🔗 SIMILARITY ANALYSIS:\")\n",
    "    print(f\"   Max Similarity: {result['max_similarity']:.4f} ({result['max_similarity']*100:.2f}%)\")\n",
    "    print(f\"   Mean Similarity: {result['mean_similarity']:.4f} ({result['mean_similarity']*100:.2f}%)\")\n",
    "    print(f\"   Meets Similarity Threshold (≥{result['similarity_threshold']}): {'✅' if result['meets_similarity'] else '❌'}\")\n",
    "    print()\n",
    "    print(\"🎯 FINAL DECISION:\")\n",
    "    print(f\"   Result: {result['final_decision']}\")\n",
    "    print(f\"   Reason: {result['decision_reason']}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Test with the current text\n",
    "print(\"Testing enhanced classification system...\")\n",
    "result = predict_intent_with_similarity(\n",
    "    text, model, tokenizer, embedding_model, \n",
    "    id2label, training_embeddings_by_intent\n",
    ")\n",
    "\n",
    "log_prediction_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2374970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING WITH MULTIPLE QUERIES\n",
      "================================================================================\n",
      "\n",
      "📋 TEST 1/14\n",
      "Query: 'Tolong tampilkan riwayat tekanan darah saya'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.833 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 2/14\n",
      "Query: 'Saya mau lihat data berat badan terakhir'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.723 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 3/14\n",
      "Query: 'Golongan darah saya apa ya?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 1.000 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 4/14\n",
      "Query: 'Cek alamat saya yang terdaftar'\n",
      "Classifier: cek_data_customer (conf: 0.999)\n",
      "Similarity: 0.831 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 5/14\n",
      "Query: 'Umur saya berapa tahun sekarang?'\n",
      "Classifier: cek_data_customer (conf: 0.693)\n",
      "Similarity: 0.996 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 6/14\n",
      "Query: 'Nomor HP saya yang tersimpan apa?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.950 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 7/14\n",
      "Query: 'Cek alamat saya yang terdaftar'\n",
      "Classifier: cek_data_customer (conf: 0.999)\n",
      "Similarity: 0.831 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 5/14\n",
      "Query: 'Umur saya berapa tahun sekarang?'\n",
      "Classifier: cek_data_customer (conf: 0.693)\n",
      "Similarity: 0.996 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 6/14\n",
      "Query: 'Nomor HP saya yang tersimpan apa?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.950 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 7/14\n",
      "Query: 'Bisa tampilkan histori suhu tubuh saya?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.754 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 8/14\n",
      "Query: 'Data medis tekanan darah saya gimana?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.700 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 9/14\n",
      "Query: 'Blood type saya apa sih?'\n",
      "Classifier: cek_data_customer (conf: 0.996)\n",
      "Similarity: 0.581 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 10/14\n",
      "Query: 'Harga iPhone 15 berapa ya?'\n",
      "Classifier: detail_preskripsi_obat (conf: 1.000)\n",
      "Similarity: 0.433 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 11/14\n",
      "Query: 'Bisa tampilkan histori suhu tubuh saya?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.754 | Final: cek_data_customer ✅ ACCEPT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 8/14\n",
      "Query: 'Data medis tekanan darah saya gimana?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.700 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 9/14\n",
      "Query: 'Blood type saya apa sih?'\n",
      "Classifier: cek_data_customer (conf: 0.996)\n",
      "Similarity: 0.581 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 10/14\n",
      "Query: 'Harga iPhone 15 berapa ya?'\n",
      "Classifier: detail_preskripsi_obat (conf: 1.000)\n",
      "Similarity: 0.433 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 11/14\n",
      "Query: 'Resep masakan ayam bakar gimana?'\n",
      "Classifier: detail_preskripsi_obat (conf: 1.000)\n",
      "Similarity: 0.609 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 12/14\n",
      "Query: 'Cuaca hari ini bagaimana?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.525 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 13/14\n",
      "Query: 'Bagaimana cara membuat website?'\n",
      "Classifier: detail_dokter (conf: 1.000)\n",
      "Similarity: 0.526 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 14/14\n",
      "Query: 'Kapan jadwal kontrol kehamilan saya?'\n",
      "Classifier: hasil_lab_detail (conf: 1.000)\n",
      "Similarity: 0.662 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "Query: 'Resep masakan ayam bakar gimana?'\n",
      "Classifier: detail_preskripsi_obat (conf: 1.000)\n",
      "Similarity: 0.609 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 12/14\n",
      "Query: 'Cuaca hari ini bagaimana?'\n",
      "Classifier: cek_data_customer (conf: 1.000)\n",
      "Similarity: 0.525 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 13/14\n",
      "Query: 'Bagaimana cara membuat website?'\n",
      "Classifier: detail_dokter (conf: 1.000)\n",
      "Similarity: 0.526 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📋 TEST 14/14\n",
      "Query: 'Kapan jadwal kontrol kehamilan saya?'\n",
      "Classifier: hasil_lab_detail (conf: 1.000)\n",
      "Similarity: 0.662 | Final: out_of_scope ❌ REJECT\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple examples including out-of-scope queries\n",
    "test_queries = [\n",
    "    # In-scope health-related queries\n",
    "    \"Tolong tampilkan riwayat tekanan darah saya\",\n",
    "    \"Saya mau lihat data berat badan terakhir\",\n",
    "    \"Golongan darah saya apa ya?\",\n",
    "    \"Cek alamat saya yang terdaftar\",\n",
    "    \"Umur saya berapa tahun sekarang?\",\n",
    "    \"Nomor HP saya yang tersimpan apa?\",\n",
    "    \n",
    "    # Edge cases - health related but might be different phrasing\n",
    "    \"Bisa tampilkan histori suhu tubuh saya?\",\n",
    "    \"Data medis tekanan darah saya gimana?\",\n",
    "    \"Blood type saya apa sih?\",\n",
    "    \n",
    "    # Clearly out-of-scope queries\n",
    "    \"Harga iPhone 15 berapa ya?\",\n",
    "    \"Resep masakan ayam bakar gimana?\",\n",
    "    \"Cuaca hari ini bagaimana?\",\n",
    "    \"Bagaimana cara membuat website?\",\n",
    "    \"Kapan jadwal kontrol kehamilan saya?\",  # This is pregnancy-related, should be out of scope\n",
    "]\n",
    "\n",
    "print(\"🧪 TESTING WITH MULTIPLE QUERIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n📋 TEST {i}/{len(test_queries)}\")\n",
    "    result = predict_intent_with_similarity(\n",
    "        query, model, tokenizer, embedding_model,\n",
    "        id2label, training_embeddings_by_intent\n",
    "    )\n",
    "    \n",
    "    # Compact logging for multiple tests\n",
    "    status = \"✅ ACCEPT\" if result['final_decision'] != 'out_of_scope' else \"❌ REJECT\"\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Classifier: {result['classifier_prediction']} (conf: {result['classifier_confidence']:.3f})\")\n",
    "    print(f\"Similarity: {result['max_similarity']:.3f} | Final: {result['final_decision']} {status}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f8bb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 ENHANCED INTENT CLASSIFICATION SYSTEM READY!\n",
      "============================================================\n",
      "📊 SYSTEM COMPONENTS:\n",
      "  • Classifier Model: IndoBERT-based (11 intent classes)\n",
      "  • Embedding Model: all-MiniLM-L6-v2\n",
      "  • Training Examples: 2081 total\n",
      "  • Intent Classes: 11\n",
      "  • Domain: General Health & Customer Data\n",
      "\n",
      "🔧 DEFAULT THRESHOLDS:\n",
      "  • Confidence Threshold: ≥ 0.7\n",
      "  • Similarity Threshold: ≥ 0.6\n",
      "\n",
      "📋 AVAILABLE INTENTS:\n",
      "  1. riwayat_kondisi_fisik (257 examples)\n",
      "  2. cek_golongan_darah (102 examples)\n",
      "  3. cek_data_customer (101 examples)\n",
      "  4. riwayat_diagnosis (255 examples)\n",
      "  5. riwayat_preskripsi_obat (204 examples)\n",
      "  6. detail_preskripsi_obat (102 examples)\n",
      "  7. riwayat_berobat (203 examples)\n",
      "  8. jadwal_dokter (202 examples)\n",
      "  9. detail_dokter (204 examples)\n",
      "  10. hasil_lab_ringkasan (251 examples)\n",
      "  11. hasil_lab_detail (200 examples)\n",
      "\n",
      "🚀 USAGE EXAMPLES:\n",
      "# Test a single query with detailed output:\n",
      "test_query('Your query here')\n",
      "\n",
      "# Test with custom thresholds:\n",
      "test_query('Your query here', confidence_threshold=0.8, similarity_threshold=0.5)\n",
      "\n",
      "# Quick test without detailed output:\n",
      "test_query('Your query here', detailed=False)\n",
      "\n",
      "============================================================\n",
      "Ready to test! Try typing: test_query('your question here')\n"
     ]
    }
   ],
   "source": [
    "# Convenient testing interface\n",
    "def test_query(query, detailed=True, confidence_threshold=0.7, similarity_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Easy-to-use function for testing individual queries\n",
    "    \"\"\"\n",
    "    result = predict_intent_with_similarity(\n",
    "        query, model, tokenizer, embedding_model,\n",
    "        id2label, training_embeddings_by_intent,\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        similarity_threshold=similarity_threshold\n",
    "    )\n",
    "    \n",
    "    if detailed:\n",
    "        log_prediction_result(result)\n",
    "    else:\n",
    "        status = \"✅ ACCEPT\" if result['final_decision'] != 'out_of_scope' else \"❌ REJECT\"\n",
    "        print(f\"'{query}' → {result['final_decision']} {status}\")\n",
    "        print(f\"  Confidence: {result['classifier_confidence']:.3f}, Similarity: {result['max_similarity']:.3f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# System summary\n",
    "print(\"🎉 ENHANCED INTENT CLASSIFICATION SYSTEM READY!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"📊 SYSTEM COMPONENTS:\")\n",
    "print(f\"  • Classifier Model: IndoBERT-based ({len(training_embeddings_by_intent)} intent classes)\")\n",
    "print(f\"  • Embedding Model: all-MiniLM-L6-v2\")\n",
    "print(f\"  • Training Examples: {sum(len(examples) for examples in training_examples_by_intent.values())} total\")\n",
    "print(f\"  • Intent Classes: {len(training_embeddings_by_intent)}\")\n",
    "print(f\"  • Domain: General Health & Customer Data\")\n",
    "\n",
    "print(\"\\n🔧 DEFAULT THRESHOLDS:\")\n",
    "print(f\"  • Confidence Threshold: ≥ 0.7\")\n",
    "print(f\"  • Similarity Threshold: ≥ 0.6\")\n",
    "\n",
    "print(\"\\n📋 AVAILABLE INTENTS:\")\n",
    "for i, (intent, count) in enumerate([(k, len(v)) for k, v in training_examples_by_intent.items()], 1):\n",
    "    print(f\"  {i}. {intent} ({count} examples)\")\n",
    "\n",
    "print(\"\\n🚀 USAGE EXAMPLES:\")\n",
    "print(\"# Test a single query with detailed output:\")\n",
    "print(\"test_query('Your query here')\")\n",
    "print(\"\\n# Test with custom thresholds:\")\n",
    "print(\"test_query('Your query here', confidence_threshold=0.8, similarity_threshold=0.5)\")\n",
    "print(\"\\n# Quick test without detailed output:\")\n",
    "print(\"test_query('Your query here', detailed=False)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready to test! Try typing: test_query('your question here')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
