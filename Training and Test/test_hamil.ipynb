{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf77a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Kapan waktu yang tepat untuk pemeriksaan kehamilan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e54f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "Model path: D:\\farrell2\\intentionBERT\\final_trained_model\n",
      "\n",
      "ðŸ” Checking files in model directory:\n",
      "   ðŸ“„ config.json (0.0 MB)\n",
      "   ðŸ“„ label_encoder.pkl (0.0 MB)\n",
      "   ðŸ“„ model.safetensors (474.7 MB)\n",
      "   ðŸ“„ special_tokens_map.json (0.0 MB)\n",
      "   ðŸ“„ tokenizer.json (0.7 MB)\n",
      "   ðŸ“„ tokenizer_config.json (0.0 MB)\n",
      "   ðŸ“„ training_metadata.json (0.0 MB)\n",
      "   ðŸ“„ vocab.txt (0.2 MB)\n",
      "\n",
      "ðŸ”„ Loading tokenizer and model...\n",
      "   âœ… Tokenizer and model loaded\n",
      "ðŸ”„ Loading label encoder...\n",
      "   âœ… Label encoder loaded\n",
      "ðŸ”„ Loading metadata...\n",
      "   Checking metadata file: D:\\farrell2\\intentionBERT\\final_trained_model\\training_metadata.json\n",
      "   âœ… Metadata file exists, attempting to load...\n",
      "   âœ… Metadata loaded successfully!\n",
      "\n",
      "ðŸ“Š TRAINING METADATA:\n",
      "----------------------------------------\n",
      "   model_name: indobenchmark/indobert-base-p1\n",
      "   num_classes: 6\n",
      "   class_names: ['anc_tracker', 'imunisasi_tracker', 'panduan_persiapan_persalinan', 'reminder_kontrol_kehamilan', 'riwayat_persalinan', 'riwayat_suplemen_kehamilan']\n",
      "   training_accuracy: 1.0000\n",
      "   training_loss: 0.0097\n",
      "\n",
      "ðŸŽ¯ Number of classes: 6\n",
      "ðŸ·ï¸ Class names: ['anc_tracker' 'imunisasi_tracker' 'panduan_persiapan_persalinan'\n",
      " 'reminder_kontrol_kehamilan' 'riwayat_persalinan'\n",
      " 'riwayat_suplemen_kehamilan']\n",
      "ðŸ’» Using device: cuda\n",
      "\n",
      "============================================================\n",
      "âœ… MODEL LOADED SUCCESSFULLY!\n",
      "============================================================\n",
      "ðŸ’» Using device: cuda\n",
      "\n",
      "============================================================\n",
      "âœ… MODEL LOADED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the trained intent classification model\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Model path\n",
    "model_path = r\"D:\\farrell2\\intentionBERT\\final_trained_model\"\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "print(f\"Model path: {model_path}\")\n",
    "\n",
    "# First, let's check what files actually exist\n",
    "print(\"\\nðŸ” Checking files in model directory:\")\n",
    "if os.path.exists(model_path):\n",
    "    files = os.listdir(model_path)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(model_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / (1024*1024)\n",
    "            print(f\"   ðŸ“„ {file} ({size_mb:.1f} MB)\")\n",
    "        else:\n",
    "            print(f\"   ðŸ“ {file}/ (directory)\")\n",
    "else:\n",
    "    print(f\"   âŒ Directory does not exist: {model_path}\")\n",
    "\n",
    "try:\n",
    "    # Load tokenizer and model\n",
    "    print(\"\\nðŸ”„ Loading tokenizer and model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    print(\"   âœ… Tokenizer and model loaded\")\n",
    "    \n",
    "    # Load label encoder\n",
    "    print(\"ðŸ”„ Loading label encoder...\")\n",
    "    label_encoder_path = os.path.join(model_path, \"label_encoder.pkl\")\n",
    "    if os.path.exists(label_encoder_path):\n",
    "        with open(label_encoder_path, \"rb\") as f:\n",
    "            label_encoder = pickle.load(f)\n",
    "        print(\"   âœ… Label encoder loaded\")\n",
    "    else:\n",
    "        print(f\"   âŒ Label encoder not found at: {label_encoder_path}\")\n",
    "        raise FileNotFoundError(\"Label encoder not found\")\n",
    "    \n",
    "    # Load metadata with detailed error checking\n",
    "    print(\"ðŸ”„ Loading metadata...\")\n",
    "    metadata_path = os.path.join(model_path, \"training_metadata.json\")\n",
    "    print(f\"   Checking metadata file: {metadata_path}\")\n",
    "    \n",
    "    if os.path.exists(metadata_path):\n",
    "        print(\"   âœ… Metadata file exists, attempting to load...\")\n",
    "        try:\n",
    "            with open(metadata_path, \"r\", encoding='utf-8') as f:\n",
    "                metadata = json.load(f)\n",
    "            print(\"   âœ… Metadata loaded successfully!\")\n",
    "            \n",
    "            # Display metadata contents\n",
    "            print(\"\\nðŸ“Š TRAINING METADATA:\")\n",
    "            print(\"-\" * 40)\n",
    "            for key, value in metadata.items():\n",
    "                if isinstance(value, float):\n",
    "                    print(f\"   {key}: {value:.4f}\")\n",
    "                elif isinstance(value, list):\n",
    "                    print(f\"   {key}: {value}\")\n",
    "                else:\n",
    "                    print(f\"   {key}: {value}\")\n",
    "                    \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"   âŒ JSON decode error: {e}\")\n",
    "            metadata = {}\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error reading metadata file: {e}\")\n",
    "            metadata = {}\n",
    "    else:\n",
    "        print(f\"   âŒ Metadata file does not exist: {metadata_path}\")\n",
    "        metadata = {}\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Number of classes: {model.config.num_labels}\")\n",
    "    print(f\"ðŸ·ï¸ Class names: {label_encoder.classes_}\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"ðŸ’» Using device: {device}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… MODEL LOADED SUCCESSFULLY!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5927ae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” DIRECT METADATA FILE INSPECTION\n",
      "==================================================\n",
      "File path: D:\\farrell2\\intentionBERT\\final_trained_model\\training_metadata.json\n",
      "File exists: True\n",
      "File size: 350 bytes\n",
      "\n",
      "ðŸ“„ Raw file contents:\n",
      "{\n",
      "  \"model_name\": \"indobenchmark/indobert-base-p1\",\n",
      "  \"num_classes\": 6,\n",
      "  \"class_names\": [\n",
      "    \"anc_tracker\",\n",
      "    \"imunisasi_tracker\",\n",
      "    \"panduan_persiapan_persalinan\",\n",
      "    \"reminder_kontrol_kehamilan\",\n",
      "    \"riwayat_persalinan\",\n",
      "    \"riwayat_suplemen_kehamilan\"\n",
      "  ],\n",
      "  \"training_accuracy\": 1.0,\n",
      "  \"training_loss\": 0.00965473335236311\n",
      "}\n",
      "\n",
      "ðŸ“Š Parsed JSON content:\n",
      "   model_name: indobenchmark/indobert-base-p1 (str)\n",
      "   num_classes: 6 (int)\n",
      "   class_names: ['anc_tracker', 'imunisasi_tracker', 'panduan_persiapan_persalinan', 'reminder_kontrol_kehamilan', 'riwayat_persalinan', 'riwayat_suplemen_kehamilan'] (list)\n",
      "   training_accuracy: 1.0 (float)\n",
      "   training_loss: 0.00965473335236311 (float)\n"
     ]
    }
   ],
   "source": [
    "# Direct inspection of the metadata file\n",
    "import json\n",
    "import os\n",
    "\n",
    "metadata_file = r\"D:\\farrell2\\intentionBERT\\final_trained_model\\training_metadata.json\"\n",
    "\n",
    "print(\"ðŸ” DIRECT METADATA FILE INSPECTION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"File path: {metadata_file}\")\n",
    "print(f\"File exists: {os.path.exists(metadata_file)}\")\n",
    "\n",
    "if os.path.exists(metadata_file):\n",
    "    # Get file info\n",
    "    file_size = os.path.getsize(metadata_file)\n",
    "    print(f\"File size: {file_size} bytes\")\n",
    "    \n",
    "    # Read raw content\n",
    "    print(\"\\nðŸ“„ Raw file contents:\")\n",
    "    try:\n",
    "        with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "            raw_content = f.read()\n",
    "        print(raw_content)\n",
    "        \n",
    "        print(\"\\nðŸ“Š Parsed JSON content:\")\n",
    "        parsed_json = json.loads(raw_content)\n",
    "        for key, value in parsed_json.items():\n",
    "            print(f\"   {key}: {value} ({type(value).__name__})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        \n",
    "        # Try different encodings\n",
    "        for encoding in ['utf-8', 'utf-8-sig', 'latin1', 'cp1252']:\n",
    "            try:\n",
    "                print(f\"\\nTrying encoding: {encoding}\")\n",
    "                with open(metadata_file, 'r', encoding=encoding) as f:\n",
    "                    content = f.read()\n",
    "                print(f\"Success with {encoding}:\")\n",
    "                print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "                break\n",
    "            except Exception as enc_error:\n",
    "                print(f\"Failed with {encoding}: {enc_error}\")\n",
    "else:\n",
    "    print(\"âŒ File does not exist!\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    model_dir = r\"D:\\farrell2\\intentionBERT\\final_trained_model\"\n",
    "    if os.path.exists(model_dir):\n",
    "        print(f\"\\nðŸ“ Files in {model_dir}:\")\n",
    "        for file in os.listdir(model_dir):\n",
    "            print(f\"   - {file}\")\n",
    "    else:\n",
    "        print(f\"âŒ Directory {model_dir} does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "997d4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ§ª TESTING THE MODEL\n",
      "============================================================\n",
      "Input text: 'Kapan waktu yang tepat untuk pemeriksaan kehamilan'\n",
      "----------------------------------------\n",
      "ðŸŽ¯ Predicted Intent: panduan_persiapan_persalinan\n",
      "ðŸŽ¯ Confidence: 0.6482 (64.82%)\n",
      "ðŸŽ¯ Class ID: 2\n",
      "\n",
      "ðŸ“Š All Class Probabilities:\n",
      "----------------------------------------\n",
      "panduan_persiapan_persalinan â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.6482 (64.82%)\n",
      "reminder_kontrol_kehamilan â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.3184 (31.84%)\n",
      "anc_tracker               â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.0198 (1.98%)\n",
      "riwayat_suplemen_kehamilan â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.0057 (0.57%)\n",
      "imunisasi_tracker         â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.0049 (0.49%)\n",
      "riwayat_persalinan        â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.0030 (0.30%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Function to predict intent for any text\n",
    "def predict_intent(text, return_all_probabilities=False):\n",
    "    \"\"\"\n",
    "    Predict the intent of a given text\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to classify\n",
    "        return_all_probabilities (bool): If True, return probabilities for all classes\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class_id].item()\n",
    "    \n",
    "    # Get predicted intent name\n",
    "    predicted_intent = label_encoder.inverse_transform([predicted_class_id])[0]\n",
    "    \n",
    "    result = {\n",
    "        'text': text,\n",
    "        'predicted_intent': predicted_intent,\n",
    "        'confidence': confidence,\n",
    "        'predicted_class_id': predicted_class_id\n",
    "    }\n",
    "    \n",
    "    if return_all_probabilities:\n",
    "        all_probs = probabilities[0].cpu().numpy()\n",
    "        class_probabilities = {}\n",
    "        for i, class_name in enumerate(label_encoder.classes_):\n",
    "            class_probabilities[class_name] = float(all_probs[i])\n",
    "        result['all_probabilities'] = class_probabilities\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the model on the text variable\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ§ª TESTING THE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Input text: '{text}'\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Make prediction\n",
    "prediction = predict_intent(text, return_all_probabilities=True)\n",
    "\n",
    "print(f\"ðŸŽ¯ Predicted Intent: {prediction['predicted_intent']}\")\n",
    "print(f\"ðŸŽ¯ Confidence: {prediction['confidence']:.4f} ({prediction['confidence']*100:.2f}%)\")\n",
    "print(f\"ðŸŽ¯ Class ID: {prediction['predicted_class_id']}\")\n",
    "\n",
    "print(\"\\nðŸ“Š All Class Probabilities:\")\n",
    "print(\"-\" * 40)\n",
    "sorted_probs = sorted(prediction['all_probabilities'].items(), \n",
    "                     key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for intent, prob in sorted_probs:\n",
    "    bar_length = int(prob * 20)  # Scale to 20 chars\n",
    "    bar = \"â–ˆ\" * bar_length + \"â–‘\" * (20 - bar_length)\n",
    "    print(f\"{intent:25} {bar} {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e999a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TESTING WITH MULTIPLE EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "1. Testing: 'saya mau liat anc tracker saya'\n",
      "------------------------------------------------------------\n",
      "   Intent: anc_tracker\n",
      "   Confidence: 0.9905 (ðŸŸ¢ HIGH)\n",
      "\n",
      "2. Testing: 'Saya merasa mual dan pusing'\n",
      "------------------------------------------------------------\n",
      "   Intent: anc_tracker\n",
      "   Confidence: 0.9827 (ðŸŸ¢ HIGH)\n",
      "\n",
      "3. Testing: 'Kapan waktu yang tepat untuk pemeriksaan kehamilan?'\n",
      "------------------------------------------------------------\n",
      "   Intent: reminder_kontrol_kehamilan\n",
      "   Confidence: 0.8693 (ðŸŸ¢ HIGH)\n",
      "\n",
      "4. Testing: 'Bagaimana cara menjaga kesehatan selama hamil?'\n",
      "------------------------------------------------------------\n",
      "   Intent: panduan_persiapan_persalinan\n",
      "   Confidence: 0.9852 (ðŸŸ¢ HIGH)\n",
      "\n",
      "5. Testing: 'Apakah normal jika perut saya terasa kencang?'\n",
      "------------------------------------------------------------\n",
      "   Intent: anc_tracker\n",
      "   Confidence: 0.7864 (ðŸŸ¡ MEDIUM)\n",
      "\n",
      "6. Testing: 'Vitamin apa yang bagus untuk ibu hamil?'\n",
      "------------------------------------------------------------\n",
      "   Intent: panduan_persiapan_persalinan\n",
      "   Confidence: 0.4788 (ðŸ”´ LOW)\n",
      "\n",
      "7. Testing: 'Saya ingin konsultasi dengan dokter'\n",
      "------------------------------------------------------------\n",
      "   Intent: anc_tracker\n",
      "   Confidence: 0.9696 (ðŸŸ¢ HIGH)\n",
      "\n",
      "================================================================================\n",
      "âœ… Testing completed! You can now use predict_intent() function with any text.\n",
      "ðŸ’¡ Usage: prediction = predict_intent('your text here')\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with additional examples to see model performance\n",
    "test_examples = [\n",
    "    \"saya mau liat anc tracker saya\",  # Your original text\n",
    "    \"Saya merasa mual dan pusing\",\n",
    "    \"Kapan waktu yang tepat untuk pemeriksaan kehamilan?\",\n",
    "    \"Bagaimana cara menjaga kesehatan selama hamil?\",\n",
    "    \"Apakah normal jika perut saya terasa kencang?\",\n",
    "    \"Vitamin apa yang bagus untuk ibu hamil?\",\n",
    "    \"Saya ingin konsultasi dengan dokter\",\n",
    "]\n",
    "\n",
    "print(\"ðŸ” TESTING WITH MULTIPLE EXAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, test_text in enumerate(test_examples, 1):\n",
    "    print(f\"\\n{i}. Testing: '{test_text}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = predict_intent(test_text)\n",
    "    \n",
    "    # Confidence level indicator\n",
    "    if result['confidence'] >= 0.8:\n",
    "        confidence_level = \"ðŸŸ¢ HIGH\"\n",
    "    elif result['confidence'] >= 0.6:\n",
    "        confidence_level = \"ðŸŸ¡ MEDIUM\" \n",
    "    else:\n",
    "        confidence_level = \"ðŸ”´ LOW\"\n",
    "    \n",
    "    print(f\"   Intent: {result['predicted_intent']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.4f} ({confidence_level})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… Testing completed! You can now use predict_intent() function with any text.\")\n",
    "print(\"ðŸ’¡ Usage: prediction = predict_intent('your text here')\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d7d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
